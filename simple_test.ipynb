{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3737de09-650e-44a6-932c-b5fe9b4a4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9862ef27-aea3-4129-aa34-a8016dbf7178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image_test/for_test (11).jpg', 'image_test/for_test (6).jpg', 'image_test/for_test (7).jpg', 'image_test/for_test (5).jpg', 'image_test/for_test (8).jpg', 'image_test/for_test (2).jpg', 'image_test/for_test (4).jpg', 'image_test/for_test (3).jpg', 'image_test/for_test (10).jpg', 'image_test/for_test (1).jpg', 'image_test/for_test (9).jpg']\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"image_test/\"\n",
    "image_path_list = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "print(image_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45a993dc-dee6-4080-8d69-572c2fb6a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"final_model/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14315b9e-ceb5-4819-9320-f5802a1f4423",
   "metadata": {},
   "source": [
    "### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2134844-b1b6-4947-adf3-a51732d7ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_test(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model = YOLO(\"final_model/weights/best.pt\")\n",
    "    results = model(image, device=\"cpu\")\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Ð’Ñ€ÐµÐ¼Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð½Ð° CPU: {end_time - start_time:.6f} ÑÐµÐºÑƒÐ½Ð´\\n\\n\")\n",
    "    \n",
    "    result_image = results[0].plot()\n",
    "    result_image = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    output_dir = \"image_predict_cpu/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    filename = os.path.basename(image_path)  \n",
    "    save_path = os.path.join(output_dir, filename)\n",
    "    \n",
    "    cv2.imwrite(save_path, cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5616904-7cf3-4e25-8037-7b99a2463246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x640 7 Persons, 4 Sneakerss, 1 Glasses, 6 Handbag/Satchels, 5 Leather Shoess, 1 Belt, 1 Backpack, 6 High Heelss, 82.5ms\n",
      "Speed: 4.7ms preprocess, 82.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Ð’Ñ€ÐµÐ¼Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð½Ð° CPU: 0.861054 ÑÐµÐºÑƒÐ½Ð´\n",
      "\n",
      "\n",
      "\n",
      "0: 480x640 1 Person, 1 Umbrella, 6 Tents, 76.8ms\n",
      "Speed: 1.7ms preprocess, 76.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Ð’Ñ€ÐµÐ¼Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð½Ð° CPU: 0.180621 ÑÐµÐºÑƒÐ½Ð´\n",
      "\n",
      "\n",
      "\n",
      "0: 448x640 4 Persons, 1 Bottle, 2 Cellos, 67.8ms\n",
      "Speed: 1.7ms preprocess, 67.8ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Ð’Ñ€ÐµÐ¼Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð½Ð° CPU: 0.177130 ÑÐµÐºÑƒÐ½Ð´\n",
      "\n",
      "\n",
      "\n",
      "0: 384x640 10 Cars, 1 SUV, 3 Sports Cars, 66.1ms\n",
      "Speed: 1.3ms preprocess, 66.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Ð’Ñ€ÐµÐ¼Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð½Ð° CPU: 0.173235 ÑÐµÐºÑƒÐ½Ð´\n",
      "\n",
      "\n",
      "\n",
      "0: 448x640 14 Chairs, 1 Couch, 41.0ms\n",
      "Speed: 1.4ms preprocess, 41.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Ð’Ñ€ÐµÐ¼Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð½Ð° CPU: 0.146681 ÑÐµÐºÑƒÐ½Ð´\n",
      "\n",
      "\n",
      "\n",
      "0: 480x640 3 Persons, 6 Sneakerss, 1 Hat, 3 Street Lightss, 5 Helmets, 1 Baseball Glove, 1 Baseball Bat, 43.8ms\n",
      "Speed: 2.0ms preprocess, 43.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Ð’Ñ€ÐµÐ¼Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð½Ð° CPU: 0.163405 ÑÐµÐºÑƒÐ½Ð´\n",
      "\n",
      "\n",
      "\n",
      "0: 448x640 1 Desk, 3 Cups, 1 Monitor/TV, 1 Pen/Pencil, 1 Cell Phone, 2 Laptops, 1 Keyboard, 1 Mouse, 41.8ms\n",
      "Speed: 1.7ms preprocess, 41.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Ð’Ñ€ÐµÐ¼Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð½Ð° CPU: 0.171701 ÑÐµÐºÑƒÐ½Ð´\n",
      "\n",
      "\n",
      "\n",
      "0: 448x640 1 Cup, 1 Plate, 1 Pizza, 41.2ms\n",
      "Speed: 1.8ms preprocess, 41.2ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Ð’Ñ€ÐµÐ¼Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð½Ð° CPU: 0.154856 ÑÐµÐºÑƒÐ½Ð´\n",
      "\n",
      "\n",
      "\n",
      "0: 224x640 3 Potted Plants, 2 Bowl/Basins, 1 Apple, 2 Pumpkins, 1 Coffee Machine, 2 Blenders, 49.7ms\n",
      "Speed: 1.1ms preprocess, 49.7ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Ð’Ñ€ÐµÐ¼Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð½Ð° CPU: 0.163277 ÑÐµÐºÑƒÐ½Ð´\n",
      "\n",
      "\n",
      "\n",
      "0: 640x640 1 Person, 2 Couchs, 68.7ms\n",
      "Speed: 2.0ms preprocess, 68.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Ð’Ñ€ÐµÐ¼Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð½Ð° CPU: 0.181846 ÑÐµÐºÑƒÐ½Ð´\n",
      "\n",
      "\n",
      "\n",
      "0: 352x640 12 Persons, 16 Cars, 1 Trash bin Can, 2 Vans, 57.6ms\n",
      "Speed: 1.4ms preprocess, 57.6ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "Ð’Ñ€ÐµÐ¼Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð½Ð° CPU: 0.300836 ÑÐµÐºÑƒÐ½Ð´\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in image_path_list:\n",
    "    cpu_test(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f85080-cdf1-418d-93cd-7c94b9f6e1c6",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d234366-2905-4bf4-9d8f-70792357742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_test(image_path):\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    model(image, device=\"cuda\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = model(image, device=\"cuda\")\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Ð’Ñ€ÐµÐ¼Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð½Ð° GPU: {end_time - start_time:.6f} ÑÐµÐºÑƒÐ½Ð´\\n\\n\")\n",
    "\n",
    "    result_image = results[0].plot()\n",
    "    result_image = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    output_dir = \"image_predict_gpu/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    filename = os.path.basename(image_path)  \n",
    "    save_path = os.path.join(output_dir, filename)\n",
    "    \n",
    "    cv2.imwrite(save_path, cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de2f374a-d44c-4fde-b06f-45f63bd6f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6ff51ae-d2ba-4368-bff3-477c12ed0a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.75 ðŸš€ Python-3.11.11 torch-2.6.0+cu124 \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 1\nos.environ['CUDA_VISIBLE_DEVICES']: -1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m image_path_list:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mgpu_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mgpu_test\u001b[39m\u001b[34m(image_path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgpu_test\u001b[39m(image_path):\n\u001b[32m      3\u001b[39m     image = Image.open(image_path)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     start_time = time.time()\n\u001b[32m      7\u001b[39m     results = model(image, device=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/yolov11/lib/python3.11/site-packages/ultralytics/engine/model.py:181\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, source, stream, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    153\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    154\u001b[39m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image.Image, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np.ndarray, torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    155\u001b[39m     stream: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    156\u001b[39m     **kwargs: Any,\n\u001b[32m    157\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m    158\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[32m    160\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    179\u001b[39m \u001b[33;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/yolov11/lib/python3.11/site-packages/ultralytics/engine/model.py:552\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, source, stream, predictor, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predictor:\n\u001b[32m    551\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor = (predictor \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._smart_load(\u001b[33m\"\u001b[39m\u001b[33mpredictor\u001b[39m\u001b[33m\"\u001b[39m))(overrides=args, _callbacks=\u001b[38;5;28mself\u001b[39m.callbacks)\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_cli\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# only update args if predictor is already setup\u001b[39;00m\n\u001b[32m    554\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor.args = get_cfg(\u001b[38;5;28mself\u001b[39m.predictor.args, args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/yolov11/lib/python3.11/site-packages/ultralytics/engine/predictor.py:312\u001b[39m, in \u001b[36mBasePredictor.setup_model\u001b[39m\u001b[34m(self, model, verbose)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msetup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    309\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Initialize YOLO model with given parameters and set it to evaluation mode.\"\"\"\u001b[39;00m\n\u001b[32m    310\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = AutoBackend(\n\u001b[32m    311\u001b[39m         weights=model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.model,\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m         device=\u001b[43mselect_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    313\u001b[39m         dnn=\u001b[38;5;28mself\u001b[39m.args.dnn,\n\u001b[32m    314\u001b[39m         data=\u001b[38;5;28mself\u001b[39m.args.data,\n\u001b[32m    315\u001b[39m         fp16=\u001b[38;5;28mself\u001b[39m.args.half,\n\u001b[32m    316\u001b[39m         batch=\u001b[38;5;28mself\u001b[39m.args.batch,\n\u001b[32m    317\u001b[39m         fuse=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    318\u001b[39m         verbose=verbose,\n\u001b[32m    319\u001b[39m     )\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m.device = \u001b[38;5;28mself\u001b[39m.model.device  \u001b[38;5;66;03m# update device\u001b[39;00m\n\u001b[32m    322\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.half = \u001b[38;5;28mself\u001b[39m.model.fp16  \u001b[38;5;66;03m# update half\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/yolov11/lib/python3.11/site-packages/ultralytics/utils/torch_utils.py:188\u001b[39m, in \u001b[36mselect_device\u001b[39m\u001b[34m(device, batch, newline, verbose)\u001b[39m\n\u001b[32m    181\u001b[39m         LOGGER.info(s)\n\u001b[32m    182\u001b[39m         install = (\n\u001b[32m    183\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    184\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCUDA devices are seen by torch.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    185\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.device_count() == \u001b[32m0\u001b[39m\n\u001b[32m    186\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    187\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    189\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid CUDA \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdevice=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m requested.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    190\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Use \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdevice=cpu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or pass valid CUDA device(s) if available,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    191\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m i.e. \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdevice=0\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdevice=0,1,2,3\u001b[39m\u001b[33m'\u001b[39m\u001b[33m for Multi-GPU.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    192\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mtorch.cuda.is_available(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.cuda.is_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    193\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mtorch.cuda.device_count(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.cuda.device_count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    194\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mos.environ[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvisible\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    195\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstall\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    196\u001b[39m         )\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cpu \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mps \u001b[38;5;129;01mand\u001b[39;00m torch.cuda.is_available():  \u001b[38;5;66;03m# prefer GPU if available\u001b[39;00m\n\u001b[32m    199\u001b[39m     devices = device.split(\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# i.e. \"0,1\" -> [\"0\", \"1\"]\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 1\nos.environ['CUDA_VISIBLE_DEVICES']: -1\n"
     ]
    }
   ],
   "source": [
    "for i in image_path_list:\n",
    "    gpu_test(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4158ec-2234-4b65-a0e5-4778c37b0e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5706ac-0e51-4d0a-9824-de8a8abc9855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ca1bd-9708-4c33-9e06-e42fbb2719a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af65bc-3c71-495f-baa9-afdeeedc7f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
